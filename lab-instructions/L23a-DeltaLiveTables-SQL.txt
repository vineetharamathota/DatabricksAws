
 Lab 23a: Delta Live Tables using SQL
 -------------------------------------
	Ref: 
	https://docs.databricks.com/en/data-governance/unity-catalog/get-started.html
	https://docs.databricks.com/en/data-governance/unity-catalog/index.html
	

 1. Login to your Databricks account and create a Workspace in us-east-1 region
 
		Name: CTSDatabricksDLT
		Region: us-east-1		
		*** Note: This takes several minutes 
		
 2. Launch Databricks UI from the databricks workspace.
 
 3. Create an All-purpose compute cluster.

	3.1 Create a single node cluster with the following details:

		Name: CTS Demo Cluster  
		Policy: Unrestricted - Single Node
		Use photon acceleration: Uncheck
		Node type: m5d.large (8 GB Memory, 2 Cores)
		Terminate after 15 minutes of inactivity
		
		* Leave all other options as defaults
		
	3.2 Click on 'Create compute' button
		
 4. Create a new notebook as below
 
	Name: L25-Delta-Live-Tables-Basics
	Type: SQL
		
	4.1 Paste the following statements in a cell.
		-> Here we are accessing /databricks-datasets that comes with databricks as sample data.

		CREATE STREAMING LIVE TABLE customers
		COMMENT "The customers buying finished products, ingested from /databricks-datasets."
		TBLPROPERTIES ("quality" = "mapping")
		AS SELECT * FROM cloud_files("/databricks-datasets/retail-org/customers/", "csv");

		CREATE STREAMING LIVE TABLE sales_orders_raw
		COMMENT "The raw sales orders, ingested from /databricks-datasets."
		TBLPROPERTIES ("quality" = "bronze")
		AS
		SELECT * FROM cloud_files("/databricks-datasets/retail-org/sales_orders/", "json", map("cloudFiles.inferColumnTypes", "true"));
		
 5. Create and run a DLT pipeline
 
	5.1 Click on 'Workflows' menu options
	
	5.2 Click on 'Delta Live Tables' and click on 'Create pipeline' button
		Pipeline name: Sales Order Pipeline
		Pipeline mode: Triggered
		Paths: Browse and select your notebook created in step 4
			ex: /Users/kanakaraju@gmail.com/L25-Delta-Live-Tables-Basics
		Minimum and maximum numbers of workers: 1 & 2
		
	5.3 Click on 'Create' to create the pipeline
	5.4 Click on 'Start' button to start the pipeline.
	
	-> Wait unitil the process is completed.
	
 6. Open the notebook (created in step 4) and paste the following code in a new cell
 
		 CREATE STREAMING LIVE TABLE sales_orders_cleaned(
		  CONSTRAINT valid_order_number EXPECT (order_number IS NOT NULL) ON VIOLATION DROP ROW
		)
		PARTITIONED BY (order_date)
		COMMENT "The cleaned sales orders with valid order_number(s) and partitioned by order_datetime."
		TBLPROPERTIES ("quality" = "silver")
		AS
		SELECT f.customer_id, f.customer_name, f.number_of_line_items,
		  TIMESTAMP(from_unixtime((cast(f.order_datetime as long)))) as order_datetime,
		  DATE(from_unixtime((cast(f.order_datetime as long)))) as order_date,
		  f.order_number, f.ordered_products, c.state, c.city, c.lon, c.lat, c.units_purchased, c.loyalty_segment
		  FROM STREAM(LIVE.sales_orders_raw) f
		  LEFT JOIN LIVE.customers c
			  ON c.customer_id = f.customer_id
			 AND c.customer_name = f.customer_name
			 
 7. Return to the Pipeline "Sales Order Pipeline".
    Select the Start dropdown next, and select "Full Refresh"


 8. Open the notebook and add the following code in a new cell. 
 
		CREATE LIVE TABLE sales_order_in_la
		COMMENT "Sales orders in LA."
		TBLPROPERTIES ("quality" = "gold")
		AS
		SELECT city, order_date, customer_id, customer_name, ordered_products_explode.curr,
		SUM(ordered_products_explode.price) as sales,
		SUM(ordered_products_explode.qty) as qantity,
		COUNT(ordered_products_explode.id) as product_count
		FROM (
		SELECT city, DATE(order_datetime) as order_date, customer_id, customer_name,
		EXPLODE(ordered_products) as ordered_products_explode
		FROM LIVE.sales_orders_cleaned
		WHERE city = 'Los Angeles'
		  )
		GROUP BY order_date, city, customer_id, customer_name, ordered_products_explode.curr;

		CREATE LIVE TABLE sales_order_in_chicago
		COMMENT "Sales orders in Chicago."
		TBLPROPERTIES ("quality" = "gold")
		AS
		SELECT city, order_date, customer_id, customer_name,
		ordered_products_explode.curr,
		SUM(ordered_products_explode.price) as sales,
		SUM(ordered_products_explode.qty) as qantity,
		COUNT(ordered_products_explode.id) as product_count
		FROM (
		  SELECT city, DATE(order_datetime) as order_date, customer_id, customer_name,
		EXPLODE(ordered_products) as ordered_products_explode
		  FROM LIVE.sales_orders_cleaned
		  WHERE city = 'Chicago'
		  )
		GROUP BY order_date, city, customer_id, customer_name, ordered_products_explode.curr;

				
 9. Return to the Pipeline "Sales Order Pipeline".
    Select the Start dropdown next, and select "Full Refresh"	
	
	
	
	
	
	
	
	
	